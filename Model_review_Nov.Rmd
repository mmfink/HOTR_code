---
title: "HOTR model evaluation"
author: "Michelle M. Fink"
date: "11/05/2019"
output:
  pdf_document: 
    fig_crop: no
    fig_height: 6
    highlight: tango
    keep_tex: yes
    theme: readable
    toc: yes
  html_document:
    fig_height: 6
    fig_width: 6
    highlight: tango
    theme: readable
    toc: yes
---
Load libraries and functions
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(stringr)
library(randomForest)
library(mgcv)
library(ROCR)
library(PresenceAbsence) # for Kappa and PCC
library(dismo) # for response curves

getConfusionMatrix <- function(tbl) {
  #https://stats.stackexchange.com/questions/35609/why-do-i-need-bag-composition-to-calculate-oob-error-of-combined-random-forest-m/35613#35613
  class.error = vector()
  
  for (i in 1:nrow(tbl)) {
    rowSum = sum(tbl[i,])
    accurate = diag(tbl)[i]
    error = rowSum - accurate
    
    class.error[i] = error / rowSum
  }   
  return(cbind(tbl, class.error))
}

opt.cut <- function(perf, pred){
  #https://www.r-bloggers.com/a-small-introduction-to-the-rocr-package/
  #calculates sensitivity = specificity threshold
  mapply(FUN=function(x, y, p){
    d = (x - 0)^2 + (y-1)^2
    ind = which(d == min(d))
    c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
      cutoff = p[[ind]])
  }, perf@x.values, perf@y.values, pred@cutoffs)
}
```

List of Completed Models:
```{r}
pth <- "H:/HOTR_models/"
RF1 <- "RF_Oct21_full.rds"
RF2 <- "RF_Oct22_full.rds"
GLM1 <- "GLMER_Oct22_full.rds"
GLM2 <- "GLM_Nov04_full.rds"
BRT1 <- "BRT_Oct28_full.rds"
GAM1 <- "BAM_Oct29_full.rds"
GAM2 <- "BAM_Nov04_full.rds"
```

## Calculate Evaluation Statistics
For each model

Note that some of these models are very large files and take a good bit of memory to load.  

### Random Forest

```{r}
rf.mod1 <- readRDS(paste0(pth,RF1))
rf.mod2 <- readRDS(paste0(pth,RF2))
```

```{r echo=FALSE}
# Add components that weren't filled in due to randomForest::combine
#https://stats.stackexchange.com/questions/35609/why-do-i-need-bag-composition-to-calculate-oob-error-of-combined-random-forest-m/35613#35613
ptab_rf.mod1 <- table(rf.mod1$predicted, rf.mod1$y)
err_rate <- 1-sum(diag(ptab_rf.mod1))/sum(ptab_rf.mod1)
rf.mod1$confusion <- getConfusionMatrix(ptab_rf.mod1)
print(RF1)
print(rf.mod1)
str_glue("OOB estimate of  error rate: {round(err_rate * 100, 3)} % ")

p_rf.mod1 <- predict(rf.mod1, type = "prob")
pred_rf.mod1 <- prediction(p_rf.mod1[,2], rf.mod1$y)
perf.roc1 <- performance(pred_rf.mod1, "tpr", "fpr")
AUC <- performance(pred_rf.mod1, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc1,pred_rf.mod1)
TSS <- sst[1] + sst[2] - 1

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_rf.mod1@predictions[[1]])),
                    OBS=as.numeric(levels(pred_rf.mod1@labels[[1]]))[pred_rf.mod1@labels[[1]]],
                    PRED=pred_rf.mod1@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- data.frame(Model = RF1, AUC = AUC, TSS = TSS, 
                    Kappa = kappa, PCC = PCC,
                    Sensitivity = sst[1], Specificity = sst[2],
                    Error_Rate = err_rate, Threshold = sst[3])

```
Start plotting stuff.  
Note that second RF model uses *GDD0* instead of *GDD5*, and drops *northness*.  
Additionally, the second model treats *nlcd* and *nearType* as factors, whereas first model treats as integers.
```{r echo=FALSE}
# Variable Importance
varImpPlot(rf.mod1, main=paste(RF1, "Variable Importance"), pch=19, color="darkblue", cex=0.9)
varImpPlot(rf.mod2, main=paste(RF2, "Variable Importance"), pch=19, color="darkblue", cex=0.9)

# ROC plot1
i <- which(perf.roc1@alpha.values[[1]] == sst[3])
plot(perf.roc1, lwd=3, col="red", asp=1, xaxs="i",
     main=paste(RF1, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc1@x.values[[1]][i], y=perf.roc1@y.values[[1]][i], pch=19, col="blue")
```


```{r echo=FALSE}
# 2nd model
ptab_rf.mod2 <- table(rf.mod2$predicted, rf.mod2$y)
err_rate <- 1-sum(diag(ptab_rf.mod2))/sum(ptab_rf.mod2)
rf.mod2$confusion <- getConfusionMatrix(ptab_rf.mod2)
print(RF2)
print(rf.mod2)
str_glue("OOB estimate of  error rate: {round(err_rate * 100, 3)} % ")

p_rf.mod2 <- predict(rf.mod2, type = "prob")
pred_rf.mod2 <- prediction(p_rf.mod2[,2], rf.mod2$y)
perf.roc2 <- performance(pred_rf.mod2, "tpr", "fpr")
AUC <- performance(pred_rf.mod2, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc2,pred_rf.mod2)
TSS <- sst[1] + sst[2] - 1

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_rf.mod2@predictions[[1]])),
                    OBS=as.numeric(levels(pred_rf.mod2@labels[[1]]))[pred_rf.mod2@labels[[1]]],
                    PRED=pred_rf.mod2@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = RF2, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot2
i <- which(perf.roc2@alpha.values[[1]] == sst[3])
plot(perf.roc2, lwd= 3, col="red", asp=1, xaxs="i", 
     main=paste(RF2, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc2@x.values[[1]][i], y=perf.roc2@y.values[[1]][i], pch=19, col="blue")
```


### Generalized Linear Mixed Model
```{r}
glm.mod1 <- readRDS(paste0(pth,GLM1))
```
This was the function call (using package **lme4**):  

> glmm.fit1 <- glmer(f_glm, data = indata, family = "binomial", control = glmerControl(optimizer = "bobyqa"), nAGQ = 0)  
See output below for formula used.
```{r}
summary(glm.mod1)
```


```{r echo=FALSE, warning=FALSE}
pred_glm.mod1 <- prediction(glm.mod1@resp$mu, glm.mod1@resp$y)
perf.roc3 <- performance(pred_glm.mod1, "tpr", "fpr")
perf.err <- performance(pred_glm.mod1, "err")
AUC <- performance(pred_glm.mod1, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc3,pred_glm.mod1)
TSS <- sst[1] + sst[2] - 1
err_rate <- perf.err@y.values[[1]][which(perf.err@x.values[[1]] == sst[3])]

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_glm.mod1@predictions[[1]])),
                    OBS=as.numeric(levels(pred_glm.mod1@labels[[1]]))[pred_glm.mod1@labels[[1]]],
                    PRED=pred_glm.mod1@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = GLM1, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot3
i <- which(perf.roc3@alpha.values[[1]] == sst[3])
plot(perf.roc3, lwd= 3, col="red", asp=1, xaxs="i", 
     main=paste(GLM1, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc3@x.values[[1]][i], y=perf.roc3@y.values[[1]][i], pch=19, col="blue")

# Response curves
#dism::response() can't handle this model
par(mfrow=c(2,2))
plot(glm.mod1, type = c("p", "smooth"), main="Residuals vs. Fitted")
plot(glm.mod1, sqrt(abs(resid(.))) ~ fitted(.), type = c("pa", "smooth"), 
     main="Homoscedasticity of the Residuals", ylim=c(0,1))
lattice::qqmath(residuals(glm.mod1), id = 0.05, main="Normal Q-Q")

```

### Generalized Linear Model (no random effects)
```{r}
glm.mod2 <- readRDS(paste0(pth,GLM2))
glm.mod2$formula
summary(glm.mod2)
```
```{r echo=FALSE, warning=FALSE}
pred_glm.mod2 <- prediction(predict(glm.mod2, type="response"), glm.mod2$y)
perf.roc4 <- performance(pred_glm.mod2, "tpr", "fpr")
perf.err <- performance(pred_glm.mod2, "err")
AUC <- performance(pred_glm.mod2, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc4,pred_glm.mod2)
TSS <- sst[1] + sst[2] - 1
err_rate <- perf.err@y.values[[1]][which(perf.err@x.values[[1]] == sst[3])]

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_glm.mod2@predictions[[1]])),
                    OBS=as.numeric(levels(pred_glm.mod2@labels[[1]]))[pred_glm.mod2@labels[[1]]],
                    PRED=pred_glm.mod2@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = GLM2, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot4
i <- which(perf.roc4@alpha.values[[1]] == sst[3])
plot(perf.roc4, lwd= 3, col="red", asp=1, xaxs="i", 
     main=paste(GLM2, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc4@x.values[[1]][i], y=perf.roc4@y.values[[1]][i], pch=19, col="blue")

par(mfrow=c(2,2))
plot(glm.mod2)

# Response curves
par(mar=c(1,1,1,1), mfrow=c(6,5))
response(glm.mod2)
```

Presumably the above was plotted in the same order as in the formula. (though would it have killed them to print labels?)

### Generalized Additive Model
This model doesn't use the Grid_ID as a random effect - so far that has not worked out (tried **gamm4** - endless loop, tried **BAM** with *s(Grid_ID, bs = 're')* in formula - ran out of memory).
```{r}
gam.mod1 <- readRDS(paste0(pth,GAM1))
```
This was the function call (using package **mgcv**):  

> ncores <- 14  
> cl <- parallel::makeCluster(ncores)  
> bip <- binomial(link = "logit")  
> gam_fit1 <- bam(f_gam, family = bip, data = indata, chunk.size = 10000, 
>                 cluster = cl)

See output below for formula used
```{r warning=FALSE}
summary(gam.mod1)
```
```{r echo=FALSE, warning=FALSE}
p_gam.mod1 <- predict(gam.mod1, type = "response")
pred_gam.mod1 <- prediction(as.vector(p_gam.mod1), gam.mod1$y)
perf.roc5 <- performance(pred_gam.mod1, "tpr", "fpr")
perf.err <- performance(pred_gam.mod1, "err")
AUC <- performance(pred_gam.mod1, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc5,pred_gam.mod1)
TSS <- sst[1] + sst[2] - 1
err_rate <- perf.err@y.values[[1]][which(perf.err@x.values[[1]] == sst[3])]

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_gam.mod1@predictions[[1]])),
                    OBS=as.numeric(levels(pred_gam.mod1@labels[[1]]))[pred_gam.mod1@labels[[1]]],
                    PRED=pred_gam.mod1@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = GAM1, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot5
i <- which(perf.roc5@alpha.values[[1]] == sst[3])
plot(perf.roc5, lwd= 3, col="red", asp=1, xaxs="i", 
     main=paste(GAM1, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc5@x.values[[1]][i], y=perf.roc5@y.values[[1]][i], pch=19, col="blue")

gam.check(gam.mod1, k.sample = 10000)
par(mfrow=c(3,4))
plot(gam.mod1, scale=0)
```

Ran various iterations using different k values and checking results with **gam.check**. The version below seemed to have the best balance between over-smoothing and over-fitting.
```{r}
gam.mod2 <- readRDS(paste0(pth,GAM2))
```
```{r warning=FALSE}
summary(gam.mod2)
```

```{r echo=FALSE, warning=FALSE}
p_gam.mod2 <- predict(gam.mod2, type = "response")
pred_gam.mod2 <- prediction(as.vector(p_gam.mod2), gam.mod2$y)
perf.roc6 <- performance(pred_gam.mod2, "tpr", "fpr")
perf.err <- performance(pred_gam.mod2, "err")
AUC <- performance(pred_gam.mod2, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc6,pred_gam.mod2)
TSS <- sst[1] + sst[2] - 1
err_rate <- perf.err@y.values[[1]][which(perf.err@x.values[[1]] == sst[3])]

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_gam.mod2@predictions[[1]])),
                    OBS=as.numeric(levels(pred_gam.mod2@labels[[1]]))[pred_gam.mod2@labels[[1]]],
                    PRED=pred_gam.mod2@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = GAM2, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot6
i <- which(perf.roc6@alpha.values[[1]] == sst[3])
plot(perf.roc6, lwd= 3, col="red", asp=1, xaxs="i", 
     main=paste(GAM2, "ROC"), xlim=c(0,1),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc6@x.values[[1]][i], y=perf.roc6@y.values[[1]][i], pch=19, col="blue")

gam.check(gam.mod2, k.sample = 10000)
plot(gam.mod2, scale=0)
```

### Boosted Regression Tree
```{r}
brt.mod1 <- readRDS(paste0(pth,BRT1))
```
```{r warning=FALSE}
print(brt.mod1)
gbm::summary.gbm(brt.mod1, cex.names=0.8, xpd=FALSE, xlim=c(0,20), 
                 las=1, mgp=c(3,0.2,0), main=paste(BRT1, "Variable Importance"))
```
```{r echo=FALSE, warning=FALSE}
p_brt.mod1 <- predict(brt.mod1, type = "response")
pred_brt.mod1 <- prediction(p_brt.mod1, brt.mod1$data$y)
perf.roc7 <- performance(pred_brt.mod1, "tpr", "fpr")
perf.err <- performance(pred_brt.mod1, "err")
AUC <- performance(pred_brt.mod1, measure = "auc")@y.values[[1]]
sst <- opt.cut(perf.roc7,pred_brt.mod1)
TSS <- sst[1] + sst[2] - 1
err_rate <- perf.err@y.values[[1]][which(perf.err@x.values[[1]] == sst[3])]

#Presence.Absence insists on its own data structure
padat <- data.frame(ID=seq(1:length(pred_brt.mod1@predictions[[1]])),
                    OBS=as.numeric(levels(pred_brt.mod1@labels[[1]]))[pred_brt.mod1@labels[[1]]],
                    PRED=pred_brt.mod1@predictions[[1]])

pacmx <- cmx(padat, threshold = sst[3])
kappa <- Kappa(pacmx, st.dev = FALSE)
PCC <- pcc(pacmx, st.dev = FALSE)

outdf <- outdf %>% add_row(Model = BRT1, AUC = AUC, TSS = TSS,
                           Kappa = kappa, PCC = PCC,
                           Sensitivity = sst[1], Specificity = sst[2],
                           Error_Rate = err_rate, Threshold = sst[3])
```
```{r echo=FALSE}
# ROC plot7
i <- which(perf.roc7@alpha.values[[1]] == sst[3])
plot(perf.roc7, lwd= 3, col="red", 
     main=paste(BRT1, "ROC"),
     sub=str_glue("AUC={round(AUC,3)}, Threshold={round(sst[3],3)}"))
abline(a=0,b=1,lwd=2,lty=2,col="gray")
points(x=perf.roc7@x.values[[1]][i], y=perf.roc7@y.values[[1]][i], pch=19, col="blue")
```
```{r echo=FALSE}
#response plots
par(mfrow=c(3,3))
gbm::plot.gbm(brt.mod1, i.var = c("GDD0"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("DEM"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("ppt_ws"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("ppt_sf"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("nlcd"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("TRI"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("distToNon"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("nlcd_patch"), n.trees = 2000, type = "response")
gbm::plot.gbm(brt.mod1, i.var = c("clay"), n.trees = 2000, type = "response")
```

**Metrics so far**
```{r paged.print=TRUE}
outdf

```